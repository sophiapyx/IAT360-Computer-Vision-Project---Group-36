{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuw5eLzQBudT2xRYJkLpLN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sophiapyx/IAT360-Computer-Vision-Project---Group-36/blob/main/Computer_Vision_Project_Group_36.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from PIL import Image\n",
        "\n",
        "base_dir = \"Desktop/datasets_cat\"\n",
        "output_dir = os.path.join(base_dir, \"converted_yolo\")\n",
        "\n",
        "class_map = {\"pain\": 1, \"no_pain\": 0}\n",
        "valid_exts = (\".png\", \".jpg\", \".jpeg\")\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "for cls in class_map:\n",
        "    os.makedirs(os.path.join(output_dir, cls, \"images\"), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_dir, cls, \"labels\"), exist_ok=True)\n",
        "\n",
        "def convert_bbox_to_yolo(bbox, img_w, img_h):\n",
        "    x_min, y_min, x_max, y_max = bbox\n",
        "    x_c = (x_min + x_max) / 2.0 / img_w\n",
        "    y_c = (y_min + y_max) / 2.0 / img_h\n",
        "    w   = (x_max - x_min) / img_w\n",
        "    h   = (y_max - y_min) / img_h\n",
        "    return x_c, y_c, w, h\n",
        "\n",
        "for cls_name, cls_id in class_map.items():\n",
        "    img_dir = os.path.join(base_dir, cls_name, \"images\")\n",
        "    label_dir = os.path.join(base_dir, cls_name, \"labels\")\n",
        "    out_img_dir = os.path.join(output_dir, cls_name, \"images\")\n",
        "    out_lbl_dir = os.path.join(output_dir, cls_name, \"labels\")\n",
        "\n",
        "    for fname in os.listdir(img_dir):\n",
        "        lf = fname.lower()\n",
        "        if not lf.endswith(valid_exts):\n",
        "            continue\n",
        "\n",
        "        base = os.path.splitext(fname)[0]\n",
        "        img_path = os.path.join(img_dir, fname)\n",
        "        json_path = os.path.join(label_dir, base + \".json\")\n",
        "\n",
        "\n",
        "        with Image.open(img_path) as im:\n",
        "            w, h = im.size\n",
        "\n",
        "\n",
        "        with open(json_path, \"r\") as f:\n",
        "            data = json.load(f)\n",
        "        bbox = data[\"bounding_boxes\"]\n",
        "\n",
        "\n",
        "        x_c, y_c, bw, bh = convert_bbox_to_yolo(bbox, w, h)\n",
        "        with open(os.path.join(out_lbl_dir, base + \".txt\"), \"w\") as f:\n",
        "            f.write(f\"{cls_id} {x_c:.6f} {y_c:.6f} {bw:.6f} {bh:.6f}\\n\")\n",
        "\n",
        "\n",
        "        with Image.open(img_path) as im:\n",
        "            im.save(os.path.join(out_img_dir, fname))\n"
      ],
      "metadata": {
        "id": "K_jmFttBK48i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 你的标签文件夹路径\n",
        "labels_dir = \"Desktop/final_datasets_cat/labels\"\n",
        "\n",
        "# 计数器\n",
        "pain_count = 0\n",
        "no_pain_count = 0\n",
        "total_files = 0\n",
        "\n",
        "# 遍历所有 txt 文件\n",
        "for file in os.listdir(labels_dir):\n",
        "    if file.endswith(\".txt\"):\n",
        "        total_files += 1\n",
        "        file_path = os.path.join(labels_dir, file)\n",
        "        with open(file_path, \"r\") as f:\n",
        "            lines = f.readlines()\n",
        "            for line in lines:\n",
        "                parts = line.strip().split()\n",
        "                if not parts:\n",
        "                    continue\n",
        "                cls = parts[0]  # 每行第一个数是类别id\n",
        "                if cls == \"1\":\n",
        "                    pain_count += 1\n",
        "                elif cls == \"0\":\n",
        "                    no_pain_count += 1\n",
        "\n",
        "# 输出结果\n",
        "print(\"📊 统计结果：\")\n",
        "print(f\"总标签文件数量: {total_files}\")\n",
        "print(f\"Pain (class 1) 标签数量: {pain_count}\")\n",
        "print(f\"No Pain (class 0) 标签数量: {no_pain_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW6ZzpVYZGh6",
        "outputId": "f85e4628-ed2e-486b-8d53-fcf13ff76e38"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 统计结果：\n",
            "总标签文件数量: 2079\n",
            "Pain (class 1) 标签数量: 266\n",
            "No Pain (class 0) 标签数量: 1831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random, shutil\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "BASE = \"Desktop/final_datasets_cat\"\n",
        "IMAGES_DIR = os.path.join(BASE, \"images\")\n",
        "LABELS_DIR = os.path.join(BASE, \"labels\")\n",
        "OUT = os.path.join(BASE, \"final_dataset\")\n",
        "\n",
        "SPLIT = 0.8\n",
        "SEED = 42\n",
        "IMG_EXTS = (\".png\", \".jpg\", \".jpeg\")\n",
        "\n",
        "\n",
        "for sub in [\"images/train\", \"images/val\", \"labels/train\", \"labels/val\"]:\n",
        "    os.makedirs(os.path.join(OUT, sub), exist_ok=True)\n",
        "\n",
        "random.seed(SEED)\n",
        "\n",
        "def stem(p):\n",
        "    return os.path.splitext(p)[0]\n",
        "\n",
        "images = {stem(f): f for f in os.listdir(IMAGES_DIR) if f.lower().endswith(IMG_EXTS)}\n",
        "labels = {stem(f): f for f in os.listdir(LABELS_DIR) if f.endswith(\".txt\")}\n",
        "\n",
        "common_keys = sorted(set(images.keys()) & set(labels.keys()))\n",
        "if not common_keys:\n",
        "    raise RuntimeError()\n",
        "\n",
        "\n",
        "def is_pain_label(txt_path):\n",
        "    with open(txt_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) >= 1 and parts[0] == \"1\":\n",
        "                return True\n",
        "    return False\n",
        "\n",
        "pain_keys = []\n",
        "nopain_keys = []\n",
        "for k in common_keys:\n",
        "    if is_pain_label(os.path.join(LABELS_DIR, labels[k])):\n",
        "        pain_keys.append(k)\n",
        "    else:\n",
        "        nopain_keys.append(k)\n",
        "\n",
        "\n",
        "def split_keys(keys, ratio):\n",
        "    n = len(keys)\n",
        "    idx = list(range(n))\n",
        "    random.shuffle(idx)\n",
        "    cut = int(n * ratio)\n",
        "    train = [keys[i] for i in idx[:cut]]\n",
        "    val   = [keys[i] for i in idx[cut:]]\n",
        "    return train, val\n",
        "\n",
        "pain_train, pain_val     = split_keys(pain_keys, SPLIT)\n",
        "nopain_train, nopain_val = split_keys(nopain_keys, SPLIT)\n",
        "\n",
        "train_keys = pain_train + nopain_train\n",
        "val_keys   = pain_val   + nopain_val\n",
        "\n",
        "def copy_pair(key, subset):\n",
        "    img_src = os.path.join(IMAGES_DIR, images[key])\n",
        "    lbl_src = os.path.join(LABELS_DIR, labels[key])\n",
        "    img_dst = os.path.join(OUT, \"images\", subset, images[key])\n",
        "    lbl_dst = os.path.join(OUT, \"labels\", subset, labels[key])\n",
        "    shutil.copy(img_src, img_dst)\n",
        "    shutil.copy(lbl_src, lbl_dst)\n",
        "\n",
        "for k in train_keys:\n",
        "    copy_pair(k, \"train\")\n",
        "for k in val_keys:\n",
        "    copy_pair(k, \"val\")\n",
        "\n",
        "yaml_path = os.path.join(OUT, \"data.yaml\")\n",
        "with open(yaml_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\n",
        "f\"\"\"# YOLO data config\n",
        "\n",
        "path: {OUT}\n",
        "train: images/train\n",
        "val: images/val\n",
        "\n",
        "nc: 2\n",
        "names:\n",
        "  0: no_pain\n",
        "  1: pain\n",
        "\"\"\"\n",
        "    )\n",
        "\n",
        "print(\"Split done!\")\n",
        "print(f\"Images with labels (pairs): {len(common_keys)}\")\n",
        "print(f\"Pain total:    {len(pain_keys)}  -> train {len(pain_train)} / val {len(pain_val)}\")\n",
        "print(f\"No-pain total: {len(nopain_keys)} -> train {len(nopain_train)} / val {len(nopain_val)}\")\n",
        "print(f\"\\n output：{OUT}\")\n",
        "print(f\"- data.yaml\")\n",
        "print(f\"- images/train, images/val\")\n",
        "print(f\"- labels/train, labels/val\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiMhOJzvZmjs",
        "outputId": "d98ebc27-5ecd-4d91-e69d-fa2351de1b5a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split done!\n",
            "Images with labels (pairs): 2079\n",
            "Pain total:    266  -> train 212 / val 54\n",
            "No-pain total: 1813 -> train 1450 / val 363\n",
            "\n",
            " output：Desktop/final_datasets_cat/final_dataset\n",
            "- data.yaml\n",
            "- images/train, images/val\n",
            "- labels/train, labels/val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxzVMe7NjSVj",
        "outputId": "b53896dc-add6-4cce-fc95-a55444233d04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "DATASET_ROOT = \"Desktop/final_datasets_cat\"\n",
        "\n",
        "IMAGES_PATH = os.path.join(DATASET_ROOT, \"images\")\n",
        "LABELS_PATH = os.path.join(DATASET_ROOT, \"labels\")\n",
        "\n",
        "if os.path.exists(IMAGES_PATH):\n",
        "    all_files = os.listdir(IMAGES_PATH)\n",
        "\n",
        "    target_extensions = ('.jpg', '.png', '.jpeg')\n",
        "\n",
        "    image_files = [f for f in all_files if not f.startswith('.') and f.lower().endswith(target_extensions)]\n",
        "    print(f\"images total: {len(image_files)}\")\n",
        "\n",
        "\n",
        "if os.path.exists(LABELS_PATH):\n",
        "    all_files = os.listdir(LABELS_PATH)\n",
        "\n",
        "    target_extensions = ('.txt',)\n",
        "\n",
        "    label_files = [f for f in all_files if not f.startswith('.') and f.lower().endswith(target_extensions)]\n",
        "    print(f\"labels total: {len(label_files)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pv1yN1J2jjaH",
        "outputId": "068fa492-8a29-44f1-ed19-db905de539e6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "images total: 2079\n",
            "labels total: 2079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ik-3rJR9k-_Y",
        "outputId": "b69e5337-836c-44bc-a982-2c81e356bc04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.220 🚀 Python-3.12.12 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 39.7/107.7 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ultralytics\n",
        "print(\"YOLOv8\", ultralytics.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ejn0Tnk4jIcN",
        "outputId": "ff92b848-9789-4fe4-f424-0c2ec80ee87f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOv8 8.3.220\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import ultralytics\n",
        "from ultralytics import YOLO\n",
        "\n",
        "ultralytics.checks()\n",
        "\n",
        "print(\"\\n--- YOLOv8 Environmental inspection completed (CPU) ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkBA0_B3m9qd",
        "outputId": "d3b5ae6a-55b0-4d03-a151-8a952cee9c01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.220 🚀 Python-3.12.12 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 39.7/107.7 GB disk)\n",
            "\n",
            "--- YOLOv8 Environmental inspection completed (CPU) ---\n"
          ]
        }
      ]
    }
  ]
}